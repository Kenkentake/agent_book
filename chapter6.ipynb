{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52cf0c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"agent-book\"\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
    "os.environ[\"COHERE_API_KEY\"] = os.getenv(\"COHERE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eec6ee5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import GitLoader\n",
    "\n",
    "def file_filter(file_path: str) -> bool:\n",
    "    # Example filter: only load .md files\n",
    "    return file_path.endswith('.md')\n",
    "\n",
    "loader = GitLoader(\n",
    "    clone_url=\"https://github.com/langchain-ai/langchain\",\n",
    "    repo_path=\"./langchain\",\n",
    "    branch=\"master\",\n",
    "    file_filter=file_filter\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2be6cd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "db = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60c73558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChainは、エージェントやLLM（大規模言語モデル）を活用したアプリケーションを構築するためのフレームワークです。このフレームワークは、相互運用可能なコンポーネントやサードパーティの統合を組み合わせることで、AIアプリケーションの開発を簡素化し、技術の進化に対応できるように設計されています。\\n\\n主な特徴としては以下があります：\\n\\n- **リアルタイムデータの拡張**：多様なデータソースやシステムにLLMを簡単に接続できる。\\n- **モデルの相互運用性**：異なるモデルを簡単に入れ替えられるため、最適な選択を迅速に行える。\\n- **迅速なプロトタイピング**：モジュール式のアーキテクチャにより、アプリケーションの構築と反復が迅速に行える。\\n- **生産準備が整った機能**：モニタリングや評価、デバッグのための統合があり、信頼性の高いアプリケーションを展開できる。\\n- **活発なコミュニティとエコシステム**：多くの統合やテンプレート、コミュニティが提供するコンポーネントを活用できる。\\n\\nLangChainは、開発者がLLMアプリケーションを構築する際に、標準的なインターフェースを提供し、さまざまな統合を通じてアプリケーションの開発を加速します。'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('''\\\n",
    "以下の文脈だけを踏まえて質問に回答してください。\n",
    "                                          \n",
    "文脈:\"\"\"\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "質問: {question}\n",
    "''')\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "chain = {\n",
    "    \"question\": RunnablePassthrough(),\n",
    "    \"context\": retriever,\n",
    "} | prompt | model | StrOutputParser()\n",
    "\n",
    "chain.invoke(\"langchainの概要を教えてください。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c15d6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChainは、エージェントやLLM（大規模言語モデル）を活用したアプリケーションを構築するためのフレームワークです。このフレームワークは、相互運用可能なコンポーネントやサードパーティの統合を組み合わせることで、AIアプリケーションの開発を簡素化し、技術の進化に対応できるように設計されています。\\n\\n主な特徴としては以下があります：\\n\\n- **リアルタイムデータの拡張**：多様なデータソースやシステムにLLMを簡単に接続できる。\\n- **モデルの相互運用性**：異なるモデルを簡単に入れ替えられるため、最適な選択を迅速に行える。\\n- **迅速なプロトタイピング**：モジュール式のアーキテクチャにより、アプリケーションの構築と反復が迅速に行える。\\n- **生産準備が整った機能**：モニタリングや評価、デバッグのための組み込みサポートがあり、信頼性の高いアプリケーションを展開できる。\\n- **活発なコミュニティとエコシステム**：豊富な統合やテンプレート、コミュニティが提供するコンポーネントを活用できる。\\n\\nLangChainは、単独で使用することもできますが、他のLangChain製品とシームレスに統合できるため、LLMアプリケーションを構築するための包括的なツールセットを提供します。'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothetical_prompt = ChatPromptTemplate.from_template('''\\\n",
    "次の質問に回答する一文を書いてください。\n",
    "                                                       \n",
    "質問: {question}\n",
    "''')\n",
    "\n",
    "hypothetical_chain = hypothetical_prompt | model | StrOutputParser()\n",
    "\n",
    "hyde_rag_chain = {\n",
    "    \"question\": RunnablePassthrough(),\n",
    "    \"context\": hypothetical_chain | retriever,\n",
    "} | prompt | model | StrOutputParser()\n",
    "\n",
    "hyde_rag_chain.invoke(\"langchainの概要を教えてください。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4776a5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class QueryGnerationOutput(BaseModel):\n",
    "    queries: list[str] = Field(description=\"検索クエリのリスト\")\n",
    "\n",
    "query_generation_prompt = ChatPromptTemplate.from_template(\"\"\"\\\n",
    "質問に対してベクターデータベースから関連文書を検索するために、\n",
    "3つの異なる検索クエリを生成してください。\n",
    "距離ベースの類似性検索の限界を克服するために、\n",
    "ユーザーの質問に対して複数の視点を提供することを目標としています。\n",
    "\n",
    "質問: {question}\n",
    "\"\"\")\n",
    "\n",
    "query_generation_chain = (\n",
    "    query_generation_prompt\n",
    "    | model.with_structured_output(QueryGnerationOutput)\n",
    "    | (lambda x: x.queries)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61cd1d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChainは、エージェントやLLM（大規模言語モデル）を活用したアプリケーションを構築するためのフレームワークです。このフレームワークは、相互運用可能なコンポーネントやサードパーティの統合を組み合わせることで、AIアプリケーションの開発を簡素化し、技術の進化に対応できるように設計されています。\\n\\n主な特徴としては以下があります：\\n\\n- **リアルタイムデータの拡張**：多様なデータソースやシステムにLLMを簡単に接続できる。\\n- **モデルの相互運用性**：異なるモデルを簡単に入れ替えられるため、最適な選択を迅速に行える。\\n- **迅速なプロトタイピング**：モジュール式のアーキテクチャにより、アプリケーションの構築と反復が迅速に行える。\\n- **生産準備が整った機能**：モニタリングや評価、デバッグのための統合が組み込まれており、信頼性の高いアプリケーションを展開できる。\\n- **活発なコミュニティとエコシステム**：多くの統合やテンプレート、コミュニティが提供するコンポーネントを活用できる。\\n\\nLangChainは、開発者がLLMアプリケーションを構築する際に、標準的なインターフェースを提供し、さまざまなモデルやツールとの統合を容易にします。'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_query_rag_chain = {\n",
    "    \"question\": RunnablePassthrough(),\n",
    "    \"context\": query_generation_chain | retriever.map(),\n",
    "} | prompt | model | StrOutputParser()\n",
    "\n",
    "multi_query_rag_chain.invoke(\"langchainの概要を教えてください。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bd2160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG-Fusion\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def reciprocal_rank_fusion(\n",
    "    retriever_outputs: list[list[Document]],\n",
    "    k: int = 60,\n",
    ") -> list[str]:\n",
    "    content_score_mapping = {}\n",
    "\n",
    "    for docs in retriever_outputs:\n",
    "        for rank, doc in enumerate(docs):\n",
    "            content = doc.page_content\n",
    "            if content not in content_score_mapping:\n",
    "                content_score_mapping[content] = 0\n",
    "            content_score_mapping[content] += 1 / (rank + k)\n",
    "\n",
    "    ranked = sorted(\n",
    "        content_score_mapping.items(), key=lambda x: x[1], reverse=True\n",
    "    )\n",
    "    return [content for content, _ in ranked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e13ea273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChainは、エージェントやLLM（大規模言語モデル）を活用したアプリケーションを構築するためのフレームワークです。このフレームワークは、相互運用可能なコンポーネントやサードパーティの統合を組み合わせることで、AIアプリケーションの開発を簡素化し、技術の進化に対応できるように設計されています。\\n\\n主な特徴としては以下があります：\\n\\n- **リアルタイムデータの拡張**：多様なデータソースやシステムにLLMを簡単に接続できる。\\n- **モデルの相互運用性**：異なるモデルを簡単に入れ替えられる。\\n- **迅速なプロトタイピング**：モジュール式のアーキテクチャにより、アプリケーションの構築と反復が迅速に行える。\\n- **生産準備が整った機能**：モニタリングや評価、デバッグのための統合が組み込まれている。\\n- **活発なコミュニティとエコシステム**：多くの統合やテンプレート、コミュニティが提供されている。\\n\\nLangChainは、開発者がLLMアプリケーションを迅速に構築できるようにするための標準インターフェースを提供し、将来的な技術の変化にも対応できる柔軟性を持っています。'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_fusion_chain = {\n",
    "    \"question\": RunnablePassthrough(),\n",
    "    \"context\": query_generation_chain | retriever.map() | reciprocal_rank_fusion,\n",
    "} | prompt | model | StrOutputParser()\n",
    "\n",
    "rag_fusion_chain.invoke(\"langchainの概要を教えてください。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e17c0afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChainは、エージェントやLLM（大規模言語モデル）を活用したアプリケーションを構築するためのフレームワークです。このプラットフォームは、相互運用可能なコンポーネントやサードパーティの統合を組み合わせることで、AIアプリケーションの開発を簡素化し、技術の進化に対応できるように設計されています。\\n\\n主な特徴としては以下があります：\\n\\n- **リアルタイムデータの拡張**：多様なデータソースやシステムにLLMを簡単に接続できる。\\n- **モデルの相互運用性**：異なるモデルを簡単に入れ替えられるため、最適な選択を迅速に行える。\\n- **迅速なプロトタイピング**：モジュール式のアーキテクチャにより、アプリケーションの構築と反復が迅速に行える。\\n- **生産準備が整った機能**：モニタリングや評価、デバッグのための統合があり、信頼性の高いアプリケーションを展開できる。\\n- **活発なコミュニティとエコシステム**：豊富な統合やテンプレート、コミュニティが提供するコンポーネントを活用できる。\\n\\nLangChainは、開発者がLLMアプリケーションを構築するための標準インターフェースを提供し、さまざまなニーズに応じた柔軟な抽象化レイヤーを持っています。'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any\n",
    "\n",
    "from langchain_cohere import CohereRerank\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def rerank(inp: dict[str, Any], top_n: int = 3) -> list[Document]:\n",
    "    question = inp[\"question\"]\n",
    "    documents = inp[\"documents\"]\n",
    "\n",
    "    cohere_reranker = CohereRerank(model=\"rerank-multilingual-v3.0\", top_n=top_n)\n",
    "    return cohere_reranker.compress_documents(documents=documents, query=question)\n",
    "\n",
    "rerank_rag_chain = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"documents\": retriever,\n",
    "    }\n",
    "    | RunnablePassthrough.assign(context=rerank)\n",
    "    | prompt | model | StrOutputParser()\n",
    ")\n",
    "\n",
    "rerank_rag_chain.invoke(\"langchainの概要を教えてください。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8850cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 複数のRetrieverを組み合わせる\n",
    "from langchain_community.retrievers import TavilySearchAPIRetriever\n",
    "\n",
    "langchain_document_retriever = retriever.with_config(\n",
    "    {\"run_name\": \"langchain_document_retriever\"}\n",
    ")\n",
    "\n",
    "web_retriever = TavilySearchAPIRetriever(k=3).with_config(\n",
    "    {\"run_name\": \"web_retriever\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32dd3777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Route(str, Enum):\n",
    "    langchain_document = \"langchain_document\"\n",
    "    web = \"web\"\n",
    "\n",
    "class RouteOutput(BaseModel):\n",
    "    route: Route\n",
    "\n",
    "route_prompt = ChatPromptTemplate.from_template(\"\"\"\\\n",
    "質問に回答するために適切なRetrieverを選択してください。\n",
    "                                                \n",
    "質問: {question}\n",
    "\"\"\")\n",
    "\n",
    "route_chain = (\n",
    "    route_prompt\n",
    "    | model.with_structured_output(RouteOutput)\n",
    "    | (lambda x: x.route)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29430e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def routed_retriever(inp: dict[str, Any]) -> list[Document]:\n",
    "    question = inp[\"question\"]\n",
    "    route = inp[\"route\"]\n",
    "\n",
    "    if route == Route.langchain_document:\n",
    "        return langchain_document_retriever.invoke(question)\n",
    "    elif route == Route.web:\n",
    "        return web_retriever.invoke(question)\n",
    "    \n",
    "    raise ValueError(f\"Unknown retriever: {retriever}\")\n",
    "\n",
    "route_rag_chain = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"route\": route_chain,\n",
    "    }\n",
    "    | RunnablePassthrough.assign(context=routed_retriever)\n",
    "    | prompt | model | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d697657e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChainは、エージェントやLLM（大規模言語モデル）を活用したアプリケーションを構築するためのフレームワークです。このフレームワークは、相互運用可能なコンポーネントやサードパーティの統合を組み合わせることで、AIアプリケーションの開発を簡素化し、技術の進化に対応できるように設計されています。\\n\\n主な特徴としては以下があります：\\n\\n- **リアルタイムデータの拡張**：多様なデータソースやシステムにLLMを簡単に接続できる。\\n- **モデルの相互運用性**：異なるモデルを簡単に入れ替えられるため、最適な選択を迅速に行える。\\n- **迅速なプロトタイピング**：モジュール式のアーキテクチャにより、アプリケーションの構築と反復が迅速に行える。\\n- **生産準備が整った機能**：モニタリングや評価、デバッグのための統合があり、信頼性の高いアプリケーションを展開できる。\\n- **活発なコミュニティとエコシステム**：多くの統合やテンプレート、コミュニティが提供するコンポーネントを活用できる。\\n\\nLangChainは、開発者がLLMアプリケーションを構築する際に、標準的なインターフェースを提供し、さまざまなニーズに応じた柔軟な抽象化レイヤーを持っています。'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route_rag_chain.invoke(\"langchainの概要を教えてください。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33eb40b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'東京の今日、11月13日(木)の天気は、南部では雲が多く、お昼ごろに雨が降る可能性があります。北部は晴れ間があるでしょう。最高気温は16度で、日差しが少ないため少しヒンヤリと感じられるかもしれません。暖かい服装でお過ごしください。お出かけには傘を持っていると安心です。'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route_rag_chain.invoke(\"東京の今日の天気を教えてください。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b89485e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "chroma_retriever = retriever.with_config(\n",
    "    {\"run_name\": \"chroma_retriever\"}\n",
    ")\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(documents).with_config(\n",
    "    {\"run_name\": \"bm25_retriever\"}\n",
    ")\n",
    "\n",
    "hybrid_retriever = (\n",
    "    RunnableParallel({\n",
    "        \"chroma_documents\": chroma_retriever,\n",
    "        \"bm25_documents\": bm25_retriever,\n",
    "    })\n",
    "    | (lambda x: [x[\"chroma_documents\"] + x[\"bm25_documents\"]])\n",
    "    | reciprocal_rank_fusion\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec4225d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChainは、エージェントやLLM（大規模言語モデル）を活用したアプリケーションを構築するためのフレームワークです。このフレームワークは、相互運用可能なコンポーネントやサードパーティの統合を組み合わせることで、AIアプリケーションの開発を簡素化し、技術の進化に対応できるように設計されています。\\n\\n主な特徴としては以下があります：\\n\\n- **リアルタイムデータの拡張**：多様なデータソースやシステムにLLMを簡単に接続できる。\\n- **モデルの相互運用性**：異なるモデルを簡単に入れ替えられる。\\n- **迅速なプロトタイピング**：モジュール式のアーキテクチャにより、アプリケーションの構築と反復が迅速に行える。\\n- **生産準備が整った機能**：モニタリングや評価、デバッグのための統合が組み込まれている。\\n- **活発なコミュニティとエコシステム**：多くの統合やテンプレート、コミュニティが提供されている。\\n\\nLangChainは、開発者がLLMアプリケーションを迅速に構築できるようにするための標準インターフェースを提供し、将来的な技術の変化にも対応できる柔軟性を持っています。'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_retriever_rag_chain = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"context\": hybrid_retriever,\n",
    "    }\n",
    "    | prompt | model | StrOutputParser()\n",
    ")\n",
    "hybrid_retriever_rag_chain.invoke(\"langchainの概要を教えてください。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c48c48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
